{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inclass material for Week 4: SQL Query using `pandas`**\n",
    "\n",
    "This notebook was made based on main materials `4_SQL_Query.ipynb`\n",
    "\n",
    "Version: Newton - March 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**START OF DAY 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Query using `pandas`\n",
    "\n",
    "**Training Objectives**\n",
    "\n",
    "- Querying from SQL Databases\n",
    "- SQL Joins\n",
    "- SQL Conditional Statements\n",
    "- Flavors and Common Operators\n",
    "- End to end data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with SQL Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Schema\n",
    "\n",
    "Database `chinook.db` terdiri dari 11 tabel yang berisi sampel data dari sebuah toko yang menjual media digital:\n",
    "\n",
    "- Data terkait media seperti pada tabel `tracks`, `albums`, `artists`, `genres`, `media_types`, `playlists`, `playlist_track` merupakan data asli dari library Apple iTunes.\n",
    "- Informasi mengenai `customers` dan `employees` dibuat menggunakan nama dan alamat fiktif yang dapat ditemukan di Google maps, dan data lain yang diformat dengan baik (telepon, fax, email, dll).\n",
    "- Informasi penjualan `invoices` dan `invoice_items` dihasilkan secara otomatis menggunakan data acak untuk periode tahun 2009-2013.\n",
    "\n",
    "Skema berikut sering disebut sebagai **Entity Relationship Diagram (ERD)**, menunjukkan:\n",
    "1. Entitas (Tabel)\n",
    "2. Atribut (Kolom beserta tipe datanya)\n",
    "3. Kardinalitas (Hubungan antar tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/chinookschema2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "\n",
    "Terdapat banyak package Python yang menyediakan fungsionalitas agar data analyst dapat bekerja dengan basis data (database). Salah satu contohnya, apabila kita ingin bekerja dengan database MySQL, maka kita dapat menggunakan `pymysql` seperti berikut:\n",
    "\n",
    "```\n",
    "import pymysql\n",
    "conn = pymysql.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    db=database)\n",
    "```\n",
    "\n",
    "Kemudian untuk membaca data kita menggunakan `pd.read_sql_query()` dan menyertakan connection yang telah dibuat:\n",
    "\n",
    "```\n",
    "sales = pd.read_sql_query(\"SELECT * FROM sales\", conn)\n",
    "```\n",
    "\n",
    "Dibalik layar, `pandas` menggunakan menggunakan [SQLAlchemy](https://www.sqlalchemy.org/) sehingga setiap database dapat bekerja. Tenang saja, hal ini bukan sesuatu yang perlu Anda khawatirkan pada pembelajaran ini. Sebagai tahap awal, mari kita coba bagaimana mengkoneksikan Jupyter Notebook dengan database SQLite (menggunakan package `sqlite3`) yang disebut sebagai **connection**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat objek connection\n",
    "conn = sqlite3.connect(\"data_input/chinook.db\")\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SELECT` Statements\n",
    "\n",
    "`SELECT` digunakan untuk memilih kolom dari sebuah tabel.\n",
    "\n",
    "Syntax `SELECT`:\n",
    "\n",
    "```\n",
    "SELECT <NAMA_KOLOM>\n",
    "FROM <NAMA_TABLE>\n",
    "```\n",
    "\n",
    "Query di bawah menunjukkan bahwa kita ingin mengambil **semua kolom** (ditandai oleh command `SELECT *`) pada tabel `albums`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query: mengambil semua kolom pada tabel albums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 **Note**: Berbeda dari Python, perintah yang ada di SQL bersifat case **insensitive**. Query di atas dapat juga dituliskan sebagai `select * from albums`. Namun, demi kemudahan pembacaan, statement biasa dituliskan dengan huruf besar (dalam hal ini `SELECT` dan `FROM`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check\n",
    "\n",
    "We'll create a `DataFrame`: this time select all columns from the `artists` table. Recall that when we use `pd.read_sql_query()` command we pass in the SQL query as a string, and add a connection as the second parameter. Save the output as a `DataFrame`.\n",
    "\n",
    "Your DataFrame should be constructed like this:\n",
    "\n",
    "`__ = pd.read_sql_query(\"SELECT __ FROM __ \", conn)`\n",
    "\n",
    "**Question:** How many rows are there in your DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan sering menggunakan parameter berikut dalam method `pd.read_sql_query()`:\n",
    "\n",
    "- `sql`: SQL query dalam bentuk string\n",
    "- `con`: SQL connection\n",
    "- `index_col`: nama atau index kolom yang ingin dijadikan index (seperti pada `pd.read_csv()`)\n",
    "- `parse_dates`: nama kolom yang ingin dikonversi menjadi tipe data `datetime64` (seperti pada `pd.read_csv()`)\n",
    "\n",
    "Silahkan kunjungi [official documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql_query.html) untuk detail lebih lanjut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIMIT\n",
    "\n",
    "Statement `LIMIT` digunakan untuk mengambil beberapa baris pertama pada data.\n",
    "\n",
    "Contoh: Ambil **5 baris pertama** dari tabel `artists` lalu jadikan kolom `ArtistId` sebuah index dengan parameter `index_col`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Joins\n",
    "\n",
    "Statement `JOIN` digunakan untuk **menggabungkan dua tabel** menjadi satu melalui kolom penghubung yang sama. Operasi `JOIN` dapat dilakukan lebih dari satu kali dalam satu SQL query. Berikut adalah diagram ilustrasi beberapa macam operasi SQL `JOIN`:\n",
    "\n",
    "![](assets/sqljoins.png)\n",
    "Credit: Data & Object Factory, LLC\n",
    "\n",
    "- `LEFT JOIN` paling sering digunakan pada sebagian besar skenario bisnis. `LEFT JOIN` mengembalikan semua baris pada tabel kiri **terlepas** dari apakah ada baris yang cocok pada tabel kanan.\n",
    "- `INNER JOIN` adalah tipe join yang sangat intuitif dan mudah dipahami. Query ini mengembalikan semua baris di tabel kiri yang cocok dengan tabel kanan.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "- `RIGHT JOIN` hampir tidak pernah digunakan karena ekuivalen dengan `LEFT JOIN` hanya mengganti peletakkan tabel kiri dan kanannya saja.\n",
    "- `FULL OUTER JOIN` sangat jarang digunakan. Selain alasan komputasi, tipe join ini mengembalikan semua baris dari kedua tabel terlepas dari apakah ada kecocokan atau tidak, sehingga menghasilkan DataFrame dengan banyak missing value.\n",
    "\n",
    "Ilustrasi terkait ke-empat tipe join dapat dilihat pada [Visual JOIN](https://joins.spathon.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax `JOIN`:\n",
    "\n",
    "```\n",
    "SELECT <COLUMNS>\n",
    "FROM <LEFT_TABLE>\n",
    "[LEFT|INNER] JOIN <RIGHT_TABLE>\n",
    "ON <LEFT_TABLE>.key = <RIGHT_TABLE>.key\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan kembali skema database `chinook.db`:\n",
    "\n",
    "1. Tabel `albums`: \n",
    "    - `AlbumId`\n",
    "    - `Title`\n",
    "    - `ArtistId`\n",
    "\n",
    "\n",
    "2. Tabel `artists`:\n",
    "    - `ArtistId`\n",
    "    - `Name` \n",
    "    \n",
    "**Kasus:** Kita ingin mendapatkan DataFrame yang menampilkan semua baris dengan kolom `AlbumId`, `Title`, dan `Name`. Perhatikan bahwa kolom `Name` terdapat pada tabel `artists`, sedangkan kolom `AlbumId` dan `Title` terdapat pada tabel `albums`.\n",
    "\n",
    "Kira-kira bagaimana strategi yang tepat? Solusi yang paling mudah adalah menggunakan `LEFT JOIN`. Mari kita lihat contohnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "albums = pd.read_sql_query(\"SELECT AlbumId, Title, Name \\\n",
    "                            FROM albums \\\n",
    "                            LEFT JOIN artists \\\n",
    "                            ON artists.ArtistId = albums.ArtistId\", conn)\n",
    "albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan SQL query di atas:\n",
    "- Tabel `albums` menjadi tabel kiri, sedangkan tabel `artists` menjadi tabel kanan.\n",
    "- Kedua tabel digabungkan menggunakan operasi `LEFT JOIN` melalui key `ArtistId`.\n",
    "- Penggunaan karakter backslash (`\\`) ditujukan agar ke-empat baris SQL query dibaca sebagai satu kesatuan baris. Namun penggunaan backslash kurang efisien dan memiliki resiko error yang lebih tinggi. Sebagai alternatif, Anda dapat mengapit SQL query dengan `'''` (petik tiga kali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-create tabel di atas menggunakan petik tiga kali '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terkadang kita memiliki nama kolom ataupun tabel yang panjang dan redundan untuk diketik.\n",
    "\n",
    "Penggunaan statement `AS` dapat digunakan untuk melakukan **aliasing** nama tabel dan nama kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-create tabel di atas menggunakan aliasing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Hati-hati! Saat melakukan `LEFT JOIN`, peletakkan tabel kiri dan kanan sangat berpengaruh. Sebagai perbanding, sekarang kita tukar tabel `artists` menjadi tabel kiri, sedangkan `albums` menjadi tabel kanan.\n",
    "\n",
    "Tabel `x` di bawah akan menampilkan semua data `artists` walaupun artist tersebut tidak ada di tabel `albums`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT AlbumId, Title, Name\n",
    "    FROM artists\n",
    "    LEFT JOIN albums\n",
    "    ON artists.ArtistId = albums.ArtistId\n",
    "    ''', conn)\n",
    "\n",
    "# cek baris dengan missing value\n",
    "x[x.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check\n",
    "\n",
    "Consider the database schema illustration again and pay attention to the following tables and their respective columns:\n",
    "\n",
    "1. `tracks`: `TrackId`, `Name`, `AlbumId`, `GenreId`, ... `UnitPrice` \n",
    "    \n",
    "2. `albums`: `AlbumId`, `Title`, `ArtistId`\n",
    "\n",
    "3. `artists`: `ArtistId`, `Name`\n",
    "\n",
    "4. `genres`: `GenreId`, `Name`\n",
    "\n",
    "**Instruction**: Create a `DataFrame` containing all columns from the `tracks` table; Additionally, it should also contain:\n",
    "\n",
    "- The `Title` column from the `albums` table\n",
    "- The `Name` column from the `artists` table\n",
    "- The `Name` column from the `genres` table\n",
    "\n",
    "> **Hint 1**: In your `SELECT` statement, you can use `SELECT tracks.* FROM TRACKS` to select all columns from the `TRACKS` table\n",
    "> \n",
    "> **Hint 2**: When we write `SELECT tracks.Name AS tracksName`, we are renaming the output column from `Name` to `tracksName` using a technique called column aliasing. You may optionally consider doing this for columns that share the same name across different tables \n",
    "\n",
    "- Set the `TrackId` column to be the index.\n",
    "- Give your `DataFrame` a name: name it `tracks`.\n",
    "- Verify: the resulting `DataFrame` should has 3503 rows and 11 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform EDA on `tracks` to answer the following question:\n",
    "\n",
    "1. Use `tail()` to inspect the last 5 rows of data. Which genre is present in the last 5 rows of our `tracks` DataFrame (Check all that apply)?\n",
    "    - [ ] Latin\n",
    "    - [ ] Classical\n",
    "    - [ ] Soundtrack\n",
    "    - [ ] Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Apply `pd.crosstab(..., columns='count')`, `.value_counts()`, or any other techniques you've learned to compute the frequency table of Genres in your DataFrame. Which is among the top 3 most represented genres in the `tracks` DataFrame?\n",
    "    - [ ] Latin\n",
    "    - [ ] Classical\n",
    "    - [ ] Soundtrack\n",
    "    - [ ] Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use `groupby()` on Artist Name and compute the `mean()` on the `UnitPrice` of each tracks. You will realize that most artists price their tracks at 0.99 (`mean`) but there are several artists where the `mean()` is 1.99. Which of the Artist has a mean of 0.99 `UnitPrice`:\n",
    "    - [ ] The Office\n",
    "    - [ ] Aquaman\n",
    "    - [ ] Pearl Jam\n",
    "    - [ ] Lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "pd.options.display.float_format = '{:.20f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Aggregation\n",
    "\n",
    "Di `pandas`, kita bisa menggunakan ketiga method berikut untuk membuat table agregasi:\n",
    "\n",
    "- `.crosstab()`\n",
    "- `.pivot_table()`\n",
    "- `.groupby()`\n",
    "\n",
    "Sedangkan di SQL, kita menggunakan statement `GROUP BY` yang diletakkan setelah `SELECT ... FROM ...`.\n",
    "\n",
    "Misal kita ingin mengetahui top 5 `CustomerId` berdasarkan jumlah besaran transaksinya (`Total`) dan juga tampilkan banyak transaksinya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_cust = pd.read_sql_query(\"SELECT CustomerId, SUM(Total) AS TotalValue, \\\n",
    "                              COUNT(InvoiceId) AS Purchases \\\n",
    "                              FROM invoices \\\n",
    "                              GROUP BY CustomerId \\\n",
    "                              ORDER BY TotalValue DESC \\\n",
    "                              LIMIT 5\", conn, index_col='CustomerId')\n",
    "top_cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-create the table above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan bagaimana query di atas dapat mengambil 5 customer teratas dari tabel `invoices`:\n",
    "\n",
    "1. Data dikelompokkan berdasarkan `CustomerId` dengan statement `GROUP BY`\n",
    "2. Terdapat dua fungsi agregasi yang digunakan: `SUM()` dan `COUNT()`, masing-masing mengagregasikan kolom `Total` dan `InvoiceId`. Perhatikan bahwa kolom yang diagregasi harus berupa data numerik dengan aggregate function: `SUM`,` AVG`, `COUNT`, ` MIN`, dan `MAX`.\n",
    "3. Statement `ORDER BY` ditambahkan untuk mengurutkan tabel berdasarkan kolom `TotalValue` secara `DESC`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 **Note**:\n",
    "\n",
    "- SQL Statement `GROUP BY` ekuivalen dengan `.groupby()` pada `pandas`\n",
    "- SQL Statement `ORDER BY` ekuivalen dengan `.sort_values()` pada `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check\n",
    "\n",
    "Edit the following code to find out the most popular `genres` from all invoice sales. Use different column to acquire the following information: Summation of `Total` sales, and number of tracks bought from the `Quantity` columns.\n",
    "\n",
    "```\n",
    "top_genre = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT genres.GenreId, genres.Name,\n",
    "    _____(invoices.Total), _____(invoice_items.Quantity)\n",
    "    FROM invoices\n",
    "    LEFT JOIN _____ ON _____\n",
    "    LEFT JOIN _____ ON _____\n",
    "    LEFT JOIN _____ ON _____\n",
    "    GROUP BY _____\n",
    "    ORDER BY _____\n",
    "    ''',\n",
    "    conn,\n",
    "    index_col='GenreId'\n",
    ")\n",
    "```\n",
    "\n",
    "**Question:** What are the top 5 genres that generated the most profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 Panduan step-by-step:\n",
    "\n",
    "1. Lakukan operasi `JOIN` tergantung dari kebutuhan kolom yang ingin dianalisis\n",
    "2. Gunakan `GROUP BY` apabila ingin membuat tabel agregasi\n",
    "3. Aplikasikan fungsi agregat di `SELECT`\n",
    "4. Tambahkan kolom yang relevan untuk ditampilkan pada `SELECT`\n",
    "5. Urutkan data menggunakan `ORDER BY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `WHERE` Statements\n",
    "\n",
    "Sampai di sini, kita telah mempelajari beberapa statement SQL yang sering digunakan:\n",
    "\n",
    "- `SELECT` statement\n",
    "- SQL `JOIN`\n",
    "- Aliasing\n",
    "- SQL Aggregation dengan `GROUP BY`\n",
    "\n",
    "Sekarang, kita akan melihat teknik untuk melakukan conditional subsetting atau filter baris menggunakan statement `WHERE` yang diikuti dengan **kondisi**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Operator\n",
    "\n",
    "- Kondisi `WHERE` dapat dikombinasikan dengan logical operator: `IS`, `AND`, `OR`, dan `NOT`:\n",
    "    - `IS` sama saja seperti notasi matematis `=`\n",
    "    - `IS NOT` seperti notasi `!=`\n",
    "    \n",
    "- Kondisi pada `WHERE` juga mendukung operator matematis seperti >, >=, <, dan <=\n",
    "\n",
    "Contoh: kita ingin melakukan analisis terhadap semua data `invoices` yang terjadi di `BillingCountry` Germany, maka kita bisa menambahkan statement `WHERE` sebagai berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM invoices\n",
    "    WHERE BillingCountry = 'Germany'\n",
    "    ''',\n",
    "    conn)\n",
    "\n",
    "# ekuivalen dengan BillingCountry IS 'Germany'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berlawanan dengan kasus di atas, misal kita ingin analisis semua data `invoices` dimana `BillingCountry` **selain** negara Germany:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM invoices\n",
    "    WHERE BillingCountry != 'Germany'\n",
    "    ''',\n",
    "    conn)\n",
    "\n",
    "# ekuivalen dengan BillingCountry IS NOT 'Germany'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kondisi yang digunakan juga dapat lebih dari satu. Misal sekarang mengambil data `invoices` yang terjadi di `BillingCountry` Canada dan juga USA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `IN` Operator\n",
    "\n",
    "Operator `IN` yang memungkinkan kita menentukan beberapa nilai untuk perbandingan. Misalnya, seperti pada kasus sebelumnya, kita ingin mengambil semua data `invoices` yang terjadi di `BillingCountry` Canada dan juga USA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "america = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM invoices\n",
    "    WHERE BillingCountry IN ('Canada', 'USA')\n",
    "    ''',\n",
    "    conn)\n",
    "\n",
    "america.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check\n",
    "\n",
    "Edit the following code to include a `WHERE` clause. We want the returned DataFrame to contain only the `Pop` genre and only when the `UnitPrice` of the track is 0.99:\n",
    "\n",
    "```\n",
    "popmusic = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT tracks.*, genres.Name AS GenreName\n",
    "    FROM _____\n",
    "    LEFT JOIN _____\n",
    "    ON _____\n",
    "    WHERE _____\n",
    "    ''',\n",
    "    conn,\n",
    "    index_col='TrackId'\n",
    ")\n",
    "```\n",
    "\n",
    "**Question:** How many rows are there in `popmusic`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating Dates\n",
    "\n",
    "Pada operasi kondisi pada statement `WHERE` sebelumnya, kita dapat mengambil semua data `invoices` pada negara Germany. Namun, juga umum untuk kita melakukan conditional query untuk mengambil data pada **rentang tanggal** tertentu.\n",
    "\n",
    "Sebelum lanjut, mari kita lihat tipe data dari objek `germany` yang telah diperoleh sebelumnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germany = pd.read_sql_query(\"SELECT * FROM invoices WHERE BillingCountry = 'Germany'\", conn)\n",
    "germany.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan bahwa `InvoiceDate` dikenali sebagai tipe data `object`. Method `pd.read_sql_query()` berperilaku seperti method `pd.read_csv()` dimana secara default membaca tipe data suatu kolom sebagai numerik dan objek. Ini tidak berarti bahwa kolom tersebut disimpan menggunakan format string (umumnya dikenal sebagai `VARCHAR` dalam database SQL). Lihatlah skema tabel berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_table = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT sql\n",
    "    FROM sqlite_master\n",
    "    WHERE name = 'invoices'\n",
    "    ''', conn)\n",
    "print(invoices_table.loc[0,:].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perlu diingat bahwa untuk DBMS yang berbeda-beda, maka cara mengambil skema tabel akan berbeda pula. Query di atas khusus untuk mengambil skema tabel dari database SQLite (`sqlite_master`).\n",
    "\n",
    "Output dari query di atas termasuk dalam tipe Data Definition Language (DDL) yang digunakan untuk membuat tabel. Dengan membaca DDL, akan berguna untuk memahami skema tabel dari database sehingga kita dapat melakukan operasi yang sesuai. Pada skema tabel `invoices` terdapat informasi yang berguna seperti:\n",
    "\n",
    "- `InvoiceId` sebagai primary key\n",
    "- `InvoiceDate` disimpan sebagai tipe data `DATETIME` (format `YYYY-MM-DD HH:MM:SS`)\n",
    "- `CustomerId` sebagai foreign key pada tabel `customers`\n",
    "\n",
    "Jika Anda tidak disediakan dengan skema database dalam bentuk diagram, maka luangkan waktu untuk mempelajari setiap skema tabel melalui DDL-nya. **Kasus**: Kita ingin meninjau penjualan (`invoices`) tahun lalu di seluruh negara pada tahun 2012 saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_2012 = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM invoices\n",
    "    WHERE InvoiceDate >= '2012-01-01' AND InvoiceDate <= '2012-12-31'\n",
    "    ''',\n",
    "    conn,\n",
    "    parse_dates='InvoiceDate'\n",
    ")\n",
    " \n",
    "invoice_2012['InvoiceDate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BETWEEN` Operator\n",
    "\n",
    "Melanjutkan kasus sebelumnya, apabila kita ingin menggunakan kondisi pada rentang tertentu, pendekatan yang umum digunakan adalah operator `BETWEEN`. Silahkan lengkapi code berikut dan lihat apakah data yang terambil sama seperti sebelumnya:\n",
    "\n",
    "```\n",
    "invoice_2012 = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM invoices\n",
    "    WHERE _____ BETWEEN '_____' AND '_____'\n",
    "    ''',\n",
    "    conn,\n",
    "    parse_dates='InvoiceDate'\n",
    ")\n",
    "\n",
    "invoice_2012['InvoiceDate'].describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ **Hati-hati!**\n",
    "\n",
    "Operator `BETWEEN` sejatinya adalah inclusive, di mana kondisi start dan endnya termasuk. Namun, saat kita membandingkan date (misal '2012-12-31') dengan datetime (pada kolom `InvoiceDate`), seakan-akan end tidak inclusive. Sebagai eksperimen, cobalah ganti kondisi pada statement `WHERE` menjadi:\n",
    "\n",
    "```\n",
    "WHERE InvoiceDate BETWEEN '2012-01-01' AND '2012-12-30'\n",
    "```\n",
    "\n",
    "Maka `InvoiceDate` pada tanggal `2012-12-30` tidak masuk.\n",
    "\n",
    "Sebagai solusinya, lebih baik kita menambahkan komponen waktu (time) pada kondisi:\n",
    "```\n",
    "WHERE InvoiceDate BETWEEN '2012-01-01 00:00:00' AND '2012-12-30 00:00:00'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bukti bahwa operator BETWEEN inclusive pada start dan end\n",
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT * FROM invoices\n",
    "    WHERE InvoiceId BETWEEN 2 AND 5\n",
    "    ''',\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masalah: ketika hanya menggunakan '2012-12-30' maka data tanggal 30 Desember 2012 TIDAK masuk\n",
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT * FROM invoices\n",
    "    WHERE InvoiceDate BETWEEN '2012-01-01' AND '2012-12-30'\n",
    "    ''',\n",
    "    conn,\n",
    "    parse_dates='InvoiceDate'\n",
    ")['InvoiceDate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solusi: masukkan komponen TIME (00:00:00) agar data transaksi pada tanggal 30 Desember 2012 juga termasuk\n",
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT * FROM invoices\n",
    "    WHERE InvoiceDate BETWEEN '2012-01-01 00:00:00' AND '2012-12-30 00:00:00'\n",
    "    ''',\n",
    "    conn,\n",
    "    parse_dates='InvoiceDate'\n",
    ")['InvoiceDate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LIKE` Operator\n",
    "\n",
    "Operator `LIKE` sangat berguna jika kita perlu mencocokan bagian tertentu dari sebuah string daripada menggunakan operator sama dengan (`=`). `'107%'` yang Anda lihat dalam query ditujukan untuk mengekstrak nilai `BillingPostalCode` yang **dimulai** dengan angka 107. Ini sangat membantu ketika Anda ingin mengekstrak data hanya pada wilayah tertentu. Di negara Germany, kita akan tahu bahwa Wilmersdorf dan Tempelhof di Berlin memiliki kode pos dimulai dengan 107.\n",
    "\n",
    "**Note:** Karakter `%` disebut juga sebagai [wildcard character](https://www.w3schools.com/sql/sql_wildcards.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT * FROM invoices\n",
    "    WHERE BillingCountry = 'Germany'\n",
    "    AND BillingPostalCode LIKE '107%'\n",
    "    ''',\n",
    "    conn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diskusi:**\n",
    "\n",
    "- Jika `BillingPostalCode LIKE '107%'`, maka semua baris dengan kode pos **dimulai** angka 107 akan tampil.\n",
    "- Jika `BillingPostalCode LIKE '%107'`, maka semua baris dengan kode pos **diakhiri** angka 107 akan tampil.\n",
    "\n",
    "Menurut Anda apa yang akan muncul jika kita menggunakan `%` **sebelum dan sesudah** pencocokan pola?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Check\n",
    "\n",
    "**Kasus**: Pada 5 data pertama `customerinv`, kita bisa melihat kolom `Company` mungkin tidak dapat diandalkan karena bernilai `None`. Tetapi jika Anda memperhatikan kolom `Email`, Anda dapat melihat beberapa customer memiliki domain email `apple`, yang bisa menjadi indikator perusahaan mereka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerinv = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT FirstName, LastName, Email, Company,\n",
    "    InvoiceId, InvoiceDate, BillingCountry, Total\n",
    "    FROM invoices\n",
    "    LEFT JOIN customers\n",
    "    ON invoices.CustomerId = customers.CustomerId\n",
    "    ''',\n",
    "    conn)\n",
    "\n",
    "customerinv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pertanyaan:** Bagaimana jika kita ingin menghitung jumlah pelanggan yang bekerja di Apple Inc. dengan menggunakan domain `Email` sebagai pengganti indikator `Company`?\n",
    "\n",
    "Silahkan lengkapi kode berikut:\n",
    "\n",
    "```\n",
    "applecust = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT firstname, lastname, email, company,\n",
    "    invoiceid, invoicedate, billingcountry, total\n",
    "    FROM invoices\n",
    "    LEFT JOIN customers\n",
    "    ON invoices._____ = customers._____\n",
    "    WHERE _____\n",
    "    ''',\n",
    "    conn\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan query tersebut, berapa pelanggan yang bekerja di Apple Inc.?\n",
    "\n",
    "- [ ] 412  \n",
    "- [ ] 49   \n",
    "- [ ] 7  \n",
    "- [ ] 14  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check 1\n",
    "\n",
    "Kita telah mempelajari banyak statement pada SQL, silahkan mencocokan statement sesuai dengan kegunaannya:\n",
    "\n",
    "**KEGUNAAN**\n",
    "\n",
    "A. Memberikan nama lain pada tabel maupun kolom\n",
    "\n",
    "B. Mengambil beberapa baris teratas dari tabel\n",
    "\n",
    "C. Mengurutkan baris berdasarkan nilai pada kolom\n",
    "\n",
    "D. Mengambil kolom dari sebuah tabel\n",
    "\n",
    "E. Menggabungkan dua tabel menjadi satu tabel berdasarkan kolom penghubung\n",
    "\n",
    "F. Filter baris\n",
    "\n",
    "G. Membuat tabel agregasi\n",
    "\n",
    "**STATEMENT**\n",
    "\n",
    "1. `SELECT <nama_kolom> FROM <nama_tabel>`\n",
    "\n",
    "2. `LIMIT <banyaknya_baris>`\n",
    "\n",
    "3. `AS <nama_kolom_atau_baris>`\n",
    "\n",
    "4. `<tabel_kiri> [LEFT|INNER] JOIN <tabel_kanan> ON <tabel>.key = <tabel>.key`\n",
    "\n",
    "5. `GROUP BY <nama_kolom>`\n",
    "\n",
    "6. `ORDER BY <nama_kolom> [ASC|DESC]`\n",
    "\n",
    "7. `WHERE <kondisi>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Check 2\n",
    "\n",
    "Susunlah 8 baris SQL statement berikut menjadi sebuah kerangka urutan syntax yang benar:\n",
    "\n",
    "1. `GROUP BY <nama_kolom>`\n",
    "\n",
    "2. `LIMIT <banyaknya_baris>`\n",
    "\n",
    "3. `SELECT <nama_kolom> AS ...`\n",
    "\n",
    "4. `[LEFT|INNER] JOIN <tabel_kanan> AS ...`\n",
    "\n",
    "5. `ORDER BY <nama_kolom> [ASC|DESC]`\n",
    "\n",
    "6. `FROM <nama_tabel> AS ...`\n",
    "\n",
    "7. `WHERE <kondisi>`\n",
    "    \n",
    "8. `ON <tabel>.key = <tabel>.key`\n",
    "\n",
    "> **JAWABAN**: Urutan yang benar adalah ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dive Deeper\n",
    "\n",
    "Toko musik digital ini ingin memberikan satu penghargaan ke `employees` yang telah bekerja keras melakukan penjualan di `BillingCountry` Amerika (yaitu **USA dan Canada**). Apabila penghargaan tersebut diberikan kepada `employees` berdasarkan **jumlah `Total`** penjualan, siapakah yang berhak mendapatkannya? Tampilkan **nama lengkap (`FirstName` dan `LastName`) beserta total penjualannya**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under and Over Fetching\n",
    "\n",
    "Di antara semua tools yang telah kita pelajari untuk menganalisis data, sekarang saatnya kita merenungkan yang mana yang lebih cocok untuk Anda. Untuk meninjau, mari kita mengingat kembali apa yang telah kita pelajari:\n",
    "\n",
    "- Reading flat files (CSV file)\n",
    "- Data cleansing and wrangling\n",
    "- Exploratory data analysis tools\n",
    "- Visual exploratory tools\n",
    "\n",
    "Kira-kira SQL masuk ke bagian apa? Untuk menjawab hal tersebut, Anda perlu memahami arsitektur client-server.\n",
    "\n",
    "![](assets/clientserver.png)\n",
    "\n",
    "Sedikit berbeda dengan `pandas` yang semua operasinya dilakukan di komputer lokal Anda. Ketika Anda bekerja dengan SQL, kemungkinan besar Anda memiliki database relasional yang disimpan terpusat pada server dan dapat diakses oleh beberapa client.\n",
    "\n",
    "Saat Anda melakukan query, sebenarnya Anda sedang menjalankan perintah untuk mengunduh data ke komputer lokal. Proses pengunduhan ini membutuhkan sumber daya dan perlu memanfaatkan alat secara efektif untuk meminimalkan biaya.\n",
    "\n",
    "- Over fetching adalah kondisi dimana kita menarik data dari database lebih dari yang dibutuhkan, sehingga membutuhkan biaya dan waktu yang lebih.\n",
    "\n",
    "- Under fetching adalah kondisi sebaliknya, dimana data yang ditarik kurang dari yang dibutuhkan, sehingga proses analisis tidak dapat dilakukan secara lengkap.\n",
    "\n",
    "**Diskusi:**\n",
    "\n",
    "Anda diminta untuk melakukan analisis terhadap semua penjualan (`invoices`) genre `Rock` pada tahun 2012. Pertimbangkan pertanyaan berikut:\n",
    "\n",
    "- Apakah perlu bagi Anda untuk mengunduh semua tabel `tracks` ke komputer lokal?\n",
    "- Apakah Anda melakukan filter baris terhadap `tracks` dengan genre `Rock` menggunakan SQL statement `WHERE` atau conditional subsetting `pandas`?\n",
    "- Karena kita memerlukan informasi dari beberapa tabel, manakah cara yang lebih nyaman: melakukan query dengan `JOIN` atau melakukan `SELECT` secara terpisah dari database?\n",
    "\n",
    "Cobalah membuat query yang paling optimum menurut Anda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) SQL Subquery\n",
    "\n",
    "Dalam beberapa kasus tertentu, kita ingin melakukan filter baris berdasarkan syarat tertentu dimana nilai-nilai kondisi didapatkan dari hasil query lain. Apakah Anda masih ingat bagaimana kita mengambil semua pelanggan yang memiliki `invoices` dengan Total paling tinggi? (Bagian SQL Aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan top 5 customers dengan total pembelanjaan terbanyak\n",
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT CustomerId, SUM(Total) AS TotalValue,\n",
    "    COUNT(InvoiceId) AS Purchases\n",
    "    FROM invoices\n",
    "    GROUP BY CustomerId\n",
    "    ORDER BY TotalValue DESC\n",
    "    LIMIT 5\n",
    "    ''',\n",
    "    conn,\n",
    "    index_col='CustomerId'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misalnya dari tabel tersebut kita ingin menarik semua data `invoices` berdasarkan top 5 `customers`. Untuk melakukan hal tersebut, kita akan menggunakan subquery setelah statement `WHERE` menggunakan operator `IN`. Sebenarnya kita bisa saja menuliskan list `CustomerId` dalam kondisi secara **hard-code** seperti ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# menampilkan invoices hanya untuk top 5 customers\n",
    "top5cust_hardcode = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM invoices\n",
    "    WHERE CustomerId IN (6, 26, 57, 45, 46)\n",
    "    ''',\n",
    "    conn)\n",
    "\n",
    "top5cust_hardcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namun cara hard-code seperti itu tidak disarankan. Bagaimana kalau database kita terus bertambah, sehingga bukan lagi `CustomerId` 6, 26, 57, 45, 46 yang merupakan top 5 customers? Maka dari itu, kita perlu menggunakan subquery agar **query kita lebih dinamis terhadap perubahan data**.\n",
    "\n",
    "Untuk itu mari kita persiapkan **subquery** yang hanya mengembalikan list Top 5 `CustomerId` berdasarkan `Total` pembelian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subquery\n",
    "pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT CustomerId\n",
    "    FROM invoices\n",
    "    GROUP BY CustomerId\n",
    "    ORDER BY SUM(Total) DESC\n",
    "    LIMIT 5\n",
    "    ''',\n",
    "    conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subquery di atas kita gunakan untuk menggantikan query yang hard-code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top5cust_subquery = pd.read_sql_query(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM invoices\n",
    "    WHERE CustomerId IN (\n",
    "        SELECT CustomerId\n",
    "        FROM invoices\n",
    "        GROUP BY CustomerId\n",
    "        ORDER BY SUM(Total) DESC\n",
    "        LIMIT 5\n",
    "    )\n",
    "    ''',\n",
    "    conn)\n",
    "\n",
    "top5cust_subquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil `top5cust_hardcode` dengan `top5cust_subquery` akan sama persis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5cust_hardcode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5cust_subquery.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newton_dwv",
   "language": "python",
   "name": "newton_dwv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.66px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
